{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports\n",
    "при подготовке семинара использованы материалы курса \"Машинное обучения\" от АТП ФИВТ МФТИ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------\n",
    "<h1 align=\"center\"> Работа с признаками </h1> \n",
    "# Предобработка данных\n",
    "скачайте данные с помощью pd.read_csv по ссылке https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data и уберите заголовок"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Считываем данные\n",
    "df = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data',)\n",
    "\n",
    "# Назначаем имена колонок\n",
    "columns = ('age workclass fnlwgt education educ-num marital-status occupation relationship '\n",
    "           'race sex capital-gain capital-loss  hours-per-week native-country salary')\n",
    "\n",
    "df.columns = columns.split() #этот метод разделит датасет по колонкам как в массиве columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "выведите первые 5 записей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "сформируйте новый датафрейм, состоящий из стоблцов 'age, salary'. Подумайте, как можно визуализировать эту информацию при помощи графиков?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = df[['age', 'salary']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Соотношение классов **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('salary').count()[['age']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Перекодировка категориальных признаков"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Работа с категориальными признаками может быть устроена по разному.\n",
    "\n",
    "В этой задаче предлагается заменить все уникальные значения таких признаков некоторым числовым значением."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Подключаем класс для предобработки данных\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# Напишем функцию, которая принимает на вход DataFrame, кодирует числовыми значениями категориальные признаки\n",
    "# и возвращает обновленный DataFrame и сами кодировщики.\n",
    "def number_encode_features(init_df):\n",
    "    result = init_df.copy() # копируем нашу исходную таблицу\n",
    "    encoders = {}\n",
    "    for column in result.columns:\n",
    "        if result.dtypes[column] == np.object: # np.object -- строковый тип / если тип столбца - строка, то нужно его закодировать\n",
    "            encoders[column] = preprocessing.LabelEncoder() # для колонки column создаем кодировщик\n",
    "            result[column] = encoders[column].fit_transform(result[column]) # применяем кодировщик к столбцу и перезаписываем столбец\n",
    "    return result, encoders\n",
    "\n",
    "encoded_data, encoders = number_encode_features(df) # Теперь encoded data содержит закодированные кат. признаки \n",
    "encoded_data.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим, во что переведены категориальные признаки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('marital-status').count()[['age']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_data.groupby('marital-status').count()[['age']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('workclass').count()[['age']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_data.groupby('workclass').count()[['age']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Гистограммы значений\n",
    "постройте графики гистограмм зависимости различных признаков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(19,8))\n",
    "cols = 5\n",
    "rows = np.ceil(float(encoded_data.shape[1]) / cols)\n",
    "for i, column in enumerate(encoded_data.columns):\n",
    "    ax = fig.add_subplot(rows, cols, i + 1)\n",
    "    ax.set_title(column)\n",
    "    encoded_data[column].hist(axes=ax)\n",
    "    plt.xticks(rotation=\"vertical\")\n",
    "plt.subplots_adjust(hspace=0.7, wspace=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Матрица корреляций\n",
    "\n",
    "По тепловой карте можно посмотреть на зависимости между признаками, а также на зависимости между целевой переменной и признаками. \n",
    "\n",
    "Положительная зависимость означает прямую зависимость (чем больше одно, тем меньше другое), отрицательная означает обратное.\n",
    "\n",
    "Значение близкое к нулю не обязательно означает отсутствие зависимости! Это лишь значит, что между признаками нет прямой (линейной) зависимости"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# тоже крутой модуль, для различной визуализации данных\n",
    "import seaborn as sns\n",
    "\n",
    "plt.subplots(figsize=(10,10))\n",
    "encoded_data, encoders = number_encode_features(df)\n",
    "sns.heatmap(encoded_data.corr(), square=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Вопрос: **\n",
    "    * Почему не всегда хорошо размечать пропуски аналогично известным значениям атрибутов\n",
    "\n",
    "В данном датасете пропущенные значения обозначены как \" ?\".  Удалим из выборки все объекты с пропусками."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# удалим все объекты, в которых содержатся пропуски\n",
    "df = df.dropna()\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Вопрос: **\n",
    "    * Почему не всегда правильно использовать перекодированные категориальные признаки (на примере kNN)?\n",
    "    \n",
    "** Предобработка данных: **\n",
    "     - разметка целевой переменной\n",
    "     - оставляем только числовые признаки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prc = df.copy()\n",
    "df_prc['salary'] = df['salary'].apply((lambda x: x==' >50K')) # Будем предсказывать 1(True), если зарплата больше 50K, 0(False) иначе\n",
    "df_prc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# числовые признаки\n",
    "df._get_numeric_data().columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Найдём категориальные признаки\n",
    "Categorical_cols = list(set(df.columns)- set(df._get_numeric_data().columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(df_prc[df._get_numeric_data().columns])\n",
    "# y = np.array(df_prc['salary'], dtype='int')\n",
    "y = encoders['salary'].transform(df['salary']) # применяем наши кодировщики к категориальным фичам"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------\n",
    "# Масштабирование признаков\n",
    "\n",
    "** Вопрос** \n",
    "* Почему для данного датасета может быть полезно привести все признаки к значениями от 0 до 1, для того чтобы использовать kNN в качестве классификатора? \n",
    "\n",
    "В качестве классификатора используем kNN, признаки: число соседей (*n_neighbors*) и метрика (*metrics*).\n",
    "\n",
    "\n",
    "Подберём оптимальные значения указанных гиперпараметров"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция отрисовки графиков\n",
    "\n",
    "def grid_plot(x, y, x_label, title, y_label='roc_auc'):\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.grid(True)\n",
    "    plt.plot(x, y, 'go-')\n",
    "    plt.xlabel(x_label)\n",
    "    plt.ylabel(y_label)\n",
    "    plt.title(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Будем использовать модель k ближайших соседей\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подбор параметра n_neighbors для KNeighborsClassifier\n",
    "\n",
    "У алгоритма knn есть один гиперпараметр (то значение, которое мы выставляем руками) -- число соседей на основе которых алгоритм принимает решение.\n",
    "\n",
    "Как обсуждалось на лекции, подбор подобных параметров можно осуществлять на основе специальной отложенной (тестовой) выборки, а можно с помощью кросс-валидации. (Вспомните, какие плюсы и минусы имеет каждый из подходов)\n",
    "\n",
    "В данной задаче мы будем использовать кросс-валидацию на 5 фолдах."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# В sklearn есть специальный модуль для работы с кросс-валидацией\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Зададим сетку - среди каких значений выбирать наилучший параметр.\n",
    "knn_grid = {'n_neighbors': np.array(np.linspace(2, 100, 10), dtype='int')} # перебираем по параметру <<n_neighbors>>, по сетке заданной np.linspace(2, 100, 10)\n",
    "\n",
    "# Создаем объект кросс-валидации\n",
    "gs = GridSearchCV(knn, knn_grid, cv=5)\n",
    "\n",
    "# Обучаем его\n",
    "gs.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Строим график зависимости качества от числа соседей\n",
    "# замечание: результаты обучения хранятся в атрибуте cv_results_ объекта gs\n",
    "\n",
    "grid_plot(knn_grid['n_neighbors'], gs.cv_results_['mean_test_score'], 'n_neighbors', 'KNeighborsClassifier')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_grid = {'n_neighbors': np.array(np.linspace(15, 35, 11), dtype='int')}\n",
    "gs = GridSearchCV(knn, knn_grid, cv=10)\n",
    "gs.fit(X, y)\n",
    "\n",
    "# best_params_ содержит в себе лучшие подобранные параметры, best_score_ лучшее качество\n",
    "gs.best_params_, gs.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_plot(knn_grid['n_neighbors'], gs.cv_results_['mean_test_score'], 'n_neighbors', 'KNeighborsClassifier')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Масштабирование признаков можно выполнить, например, одним из следующих способов способами:\n",
    " - $x_{new} = \\dfrac{x - \\mu}{\\sigma}$, где $\\mu, \\sigma$ — среднее и стандартное отклонение значения признака по всей выборке (см. функцию [scale](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.scale.html))\n",
    " - $x_{new} = \\dfrac{x - x_{min}}{x_{max} - x_{min}}$, где $[x_{min}, x_{max}]$ — минимальный интервал значений признака"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import scale\n",
    "X_scaled = scale(np.array(X, dtype='float'), with_std=True, with_mean=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подборка параметра n_neighbors для KNeighborsClassifier при нормированных признаках"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = {'n_neighbors': np.array(np.linspace(1, 100, 10), dtype='int')}\n",
    "gs = GridSearchCV(knn, grid, cv=5, n_jobs=5)\n",
    "gs.fit(X_scaled, y)\n",
    "print(gs.best_params_, gs.best_score_)\n",
    "grid_plot(grid['n_neighbors'], gs.cv_results_['mean_test_score'], 'n_neighbors', 'KNeighborsClassifier')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = {'n_neighbors': np.array(np.linspace(55, 75, 21), dtype='int')}\n",
    "gs = GridSearchCV(knn, grid, cv=10, n_jobs=5)\n",
    "gs.fit(X_scaled, y)\n",
    "print(gs.best_params_, gs.best_score_)\n",
    "grid_plot(grid['n_neighbors'], gs.cv_results_['mean_test_score'], 'n_neighbors', 'KNeighborsClassifier')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Вопрос ** \n",
    " * Увеличилась ли точность классификации после нормировки?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=\"center\"> Метрики </h1> \n",
    "# Метрики для задачи классификации\n",
    "### Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Поделим выборку на train/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_tain, y_test = train_test_split(X,y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Используем 2 классификаторва \n",
    "- умный kNN\n",
    "- глупый -- DummyClassifier (самый популярный класс)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import dummy\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=29) \n",
    "clf_knn = knn.fit(X_train, y_tain)\n",
    "clf_mp = dummy.DummyClassifier(\"most_frequent\").fit(X_train, y_tain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_knn = clf_knn.predict(X_test)\n",
    "y_mp = clf_mp.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $$Accuracy = \\frac{\\sum_{x_i, y_i \\in (X, Y)} I(y(x_i) = y_i)}{|(X, Y)|} = \\frac{num~right~classified~obj}{num~all~obj}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "print ('knn =', metrics.accuracy_score(y_test, y_knn), 'mp =', metrics.accuracy_score(y_test, y_mp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Вопросы **\n",
    "* На самом ли деле kNN выдает настолько плохие предсказания?\n",
    "* Какую использовать метрику точности предсказаний при несбалансированных классах?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conf-matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "\n",
    "fig = plt.figure(figsize=(10,8))\n",
    "nn_mtx = metrics.confusion_matrix(y_test, y_knn)\n",
    "\n",
    "font = {'family' : 'Calibri', 'weight' : 'bold', 'size'   :22}\n",
    "matplotlib.rc('font', **font)\n",
    "matplotlib.rc('xtick', labelsize=20) \n",
    "matplotlib.rc('ytick', labelsize=20) \n",
    "sns.heatmap(nn_mtx, annot=True, fmt=\"d\", \n",
    "            xticklabels=encoders[\"salary\"].classes_, \n",
    "            yticklabels=encoders[\"salary\"].classes_)\n",
    "plt.ylabel(\"Real value\")\n",
    "plt.xlabel(\"Predicted value\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_mtx = metrics.confusion_matrix(y_test, y_mp)\n",
    "\n",
    "font = {'family' : 'Calibri', 'weight' : 'bold', 'size'   :22}\n",
    "matplotlib.rc('font', **font)\n",
    "fig = plt.figure(figsize=(10,8))\n",
    "sns.heatmap(mp_mtx, annot=True, fmt=\"d\", \n",
    "            xticklabels=encoders[\"salary\"].classes_, \n",
    "            yticklabels=encoders[\"salary\"].classes_)\n",
    "plt.ylabel(\"Real value\")\n",
    "plt.xlabel(\"Predicted value\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $$Precision = \\frac{TP}{TP + FP}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('knn =', metrics.precision_score(y_test, y_knn), 'mp =', metrics.precision_score(y_test, y_mp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Вопрос: **\n",
    "* Приведите пример работы классификатора когда precition большой а классификатор работает плохо?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $$Recall = \\frac{TP}{TP + FN}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('knn =', metrics.recall_score(y_test, y_knn), 'mp =', metrics.recall_score(y_test, y_mp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Вопрос: ** \n",
    "* Приведите пример работы классификатора когда recall большой а классификатор работает плохо?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### F1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Что важнее, точность или полнота? Какое среднее выбрать?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $$F1 = 2 \\cdot \\frac{Precision \\cdot Recall}{Precision + Recall}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Вопросы: ** \n",
    "* Как взвесить Precision и Recall?\n",
    "    - Среднее арифметичиское плохо: (p=0.5, r=0.5) должно быть лучше чем (p=1, r=0), \n",
    "    - Лучше минимум, но при равной точности должен побеждать классфикатор с большей полнотой\n",
    "    - Гармоничиское среднее, сглаженный минимум"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "\n",
    "fig, axs = plt.subplots(figsize=(18, 5), ncols=3)\n",
    "\n",
    "x_, y_ = np.arange(0.01, 1, 0.01), np.arange(0.01, 1, 0.01)\n",
    "X, Y = np.meshgrid(x_, y_)\n",
    "\n",
    "Z = [[0.5*x + 0.5*y  for x in x_] for y in y_]\n",
    "axs[0].contour(X, Y, Z)\n",
    "axs[0].set_title('mean')\n",
    "axs[0].set_xlabel('Presition')\n",
    "axs[0].set_ylabel('Recall')\n",
    "\n",
    "Z = [[min(x, y)  for x in x_] for y in y_]\n",
    "axs[1].contour(X, Y, Z)\n",
    "axs[1].set_title('min')\n",
    "axs[1].set_xlabel('Presition')\n",
    "axs[1].set_ylabel('Recall')\n",
    "\n",
    "\n",
    "Z = [[scipy.stats.hmean([x, y])  for x in x_] for y in y_]\n",
    "axs[2].contour(X, Y, Z)\n",
    "axs[2].set_title('harmonik')\n",
    "axs[2].set_xlabel('Presition')\n",
    "axs[2].set_ylabel('Recall')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('knn =', metrics.f1_score(y_test, y_knn), 'mp =', metrics.f1_score(y_test, y_mp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:orange\"> Multiclass Precision-Recall </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Загрузим датасет с тремя классами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_iris = sns.load_dataset(\"iris\")\n",
    "df_iris = df_iris.sample(n=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matplotlib.rc('xtick', labelsize=10) \n",
    "matplotlib.rc('ytick', labelsize=10)\n",
    "sns.pairplot(df_iris, hue=\"species\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_iris, encoders = number_encode_features(df_iris)\n",
    "iris_X, iris_y = df_iris[df_iris.columns[:-1]].values, df_iris[df_iris.columns[-1]].values\n",
    "\n",
    "iris_X_train, iris_y_tain = iris_X[:30], iris_y[:30]\n",
    "iris_X_test, iris_y_test = iris_X[40:], iris_y[40:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_iris.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_clf_knn = KNeighborsClassifier().fit(iris_X_train, iris_y_tain)\n",
    "iris_clf_mp = dummy.DummyClassifier(\"most_frequent\").fit(iris_X_train, iris_y_tain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_y_knn = iris_clf_knn.predict(iris_X_test)\n",
    "iris_y_mp = iris_clf_mp.predict(iris_X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пусть выборка состоит из K классов. Рассмотрим K двухклассовых задач, каждая из которых заключается в отделении своего класса от остальных, то есть целевые значения для k-й задаче вычисляются как $y_{ik} = [yi = k]$. Для каждой из них можно вычислить различные характеристики (TP, FP, и т.д.) алгоритма $a_k(x) = [a(x) = k]$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_mtx = metrics.confusion_matrix(iris_y_test, iris_y_knn)\n",
    "\n",
    "fig = plt.figure(figsize=(10,8))\n",
    "matplotlib.rc('xtick', labelsize=15) \n",
    "matplotlib.rc('ytick', labelsize=15)\n",
    "sns.heatmap(mp_mtx, annot=True, fmt=\"d\", \n",
    "            xticklabels=encoders[\"species\"].classes_, \n",
    "            yticklabels=encoders[\"species\"].classes_)\n",
    "plt.ylabel(\"Real value\")\n",
    "plt.xlabel(\"Predicted value\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Macro-averaging** -- подсчет TP, FN, TN, FP для каждого класса, а после подсчет точности и полноты.\n",
    "\n",
    "**Micro-averaging** -- подсчет  точности и полноты для каждого класса, а после подсчет их среденего."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('для kNN:')\n",
    "print ('macro = ', metrics.f1_score(iris_y_test, iris_y_knn, average='macro'), ', micro = ', metrics.f1_score(iris_y_test, iris_y_knn, average='micro'))\n",
    "\n",
    "# \n",
    "print('\\nдля dummy-classifier:')\n",
    "iris_y_knn[iris_y_knn==1] = 0\n",
    "print ('macro = ', metrics.f1_score(iris_y_test, iris_y_knn, average='macro'), ', micro = ', metrics.f1_score(iris_y_test, iris_y_knn, average='micro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AUC-ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_knn = KNeighborsClassifier(n_neighbors=29).fit(X_train, y_tain)\n",
    "clf_mp = dummy.DummyClassifier(\"most_frequent\").fit(X_train, y_tain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_knn = clf_knn.predict(X_test)\n",
    "y_mp = clf_mp.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, _ = metrics.roc_curve(y_test, y_knn)\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.plot(fpr, tpr)\n",
    "print ('ROC AUC = {0:.4f}'.format(metrics.auc(fpr, tpr)))\n",
    "plt.ylabel(\"True Positive Rate\", fontsize=20)\n",
    "plt.xlabel(\"False Positive Rate\", fontsize=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, _ = metrics.roc_curve(y_test, y_mp)\n",
    "pylab.figure(figsize=(10, 7))\n",
    "pylab.plot([0, 1], [0, 1], 'k--')\n",
    "pylab.plot(fpr, tpr)\n",
    "print ('ROC AUC = {0:.4f}'.format(metrics.auc(fpr, tpr)))\n",
    "plt.ylabel(\"True Positive Rate\", fontsize=20)\n",
    "plt.xlabel(\"False Positive Rate\", fontsize=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Вопрос **\n",
    "* Когда AUC большой при плохой работе классификатора?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PR AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pres, rec, _ = metrics.precision_recall_curve(y_test, y_knn)\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(pres, rec)\n",
    "plt.ylabel('presicion', fontsize=20)\n",
    "plt.xlabel('recall', fontsize=20)\n",
    "print ('PR AUC = {0:.4f}'.format(metrics.auc(pres, rec)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pres, rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pres, rec, _ = metrics.precision_recall_curve(y_test, y_mp)\n",
    "pylab.figure(figsize=(8, 6))\n",
    "pylab.plot(rec, pres)\n",
    "pylab.ylabel('pres')\n",
    "pylab.xlabel('rec')\n",
    "print( 'PR AUC = {0:.4f}'.format(metrics.auc(pres, rec)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Когда PR кривая не адекватна?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Метрики для задачи рeгрессии"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data: https://archive.ics.uci.edu/ml/datasets/Wine+Quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-white.csv', header=0, sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.hist(figsize=(18, 8), layout=(3,4), bins=20, alpha=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df.drop('quality', axis=1), df.quality, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (X_train.shape, X_test.shape)\n",
    "print (y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "\n",
    "# Create linear regression object\n",
    "regr = linear_model.LinearRegression()\n",
    "\n",
    "# Train the model using the training sets\n",
    "regr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dummy regression object\n",
    "d_regr = dummy.DummyRegressor(strategy='mean')\n",
    "\n",
    "# Train the model using the training sets\n",
    "d_regr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = regr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_predictions = d_regr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (predictions.shape, '\\t', predictions[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (d_predictions.shape, '\\t', d_predictions[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rem = predictions - y_test\n",
    "plt.figure(figsize=(15, 8))\n",
    "plt.hist(rem, bins=50, normed=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean Square Error "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $$ MSE(y, \\hat y) = \\frac{1}{n_{samples}} \\sum_{i=1}^{n_{samples}} ( y_i - \\hat y_i )^2 $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = metrics.mean_squared_error(y_test, predictions)\n",
    "d_mse = metrics.mean_squared_error(y_test, d_predictions)\n",
    "\n",
    "print (\"MSE,  LR = {0:.4}, Dummy = {1:0.4}\".format(mse, d_mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse = np.sqrt(mse)\n",
    "d_rmse = np.sqrt(d_mse)\n",
    "\n",
    "print( \"RMSE / LR = {0:.4}, Dummy = {1:0.4}\".format(rmse, d_rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean Absolute Error "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $$ MAE(y, \\hat y) = \\frac{1}{n_{samples}} \\sum_{i=1}^{n_{samples}} | y_i - \\hat y_i | $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mae = metrics.mean_absolute_error(y_test, predictions)\n",
    "d_mae = metrics.mean_absolute_error(y_test, d_predictions)\n",
    "\n",
    "print( \"MAE / LR = {0:.4}, Dummy = {1:0.4}\".format(mae, d_mae))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Median Absolute Error "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $$ MedAE(y, \\hat y) = median( | y_1 - \\hat y_1 |, ..., | y_n - \\hat y_n | ) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "medae = metrics.median_absolute_error(y_test, predictions)\n",
    "d_medae = metrics.median_absolute_error(y_test, d_predictions)\n",
    "\n",
    "print (\"MedAE / LR = {0:.4}, Dummy = {1:0.4}\".format(medae, d_medae))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### R² score, the coefficient of determination"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $$ R^2(y, \\hat y) = 1 -  \\frac{\\sum_{i=1}^{n_{samples}} ( y_i - \\hat y_i )^2}{\\sum_{i=1}^{n_{samples}} {( y_i - \\bar y_i )^2}} $$\n",
    "\n",
    "## $ \\bar y = \\frac{1}{n_{samples}} \\sum_{i=1}^{n_{samples}} y_i $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2 = metrics.r2_score(y_test, predictions)\n",
    "d_r2 = metrics.r2_score(y_test, d_predictions)\n",
    "\n",
    "print (\"R2 score / LR = {0:.4}, Dummy = {1:0.4}\".format(r2, d_r2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Как интерпретировать MSE, RMSE, MAE, MedAE?</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Интепретация метрик с вероятностной точки зрения"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Функционал среднего риска\n",
    "$$R(a) = \\sum\\limits_{X}\\sum\\limits_{Y}\\lambda_{ya(x)}P\\left(y|x\\right)p(x)dx=\\int\\limits_{X}\\sum\\limits_{Y}\\lambda_{ya(x)}P\\left(y|x\\right)p(x)dx $$\n",
    "* paragraph 2.1 http://www.machinelearning.ru/wiki/images/6/6d/Voron-ML-1.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Задача 1** \n",
    "<img src='img/Task2.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Задача 2** \n",
    "<img src='img/Task3.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=\"center\"> Bias-Variance TradeOff </h1> \n",
    "# Проблема переобучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overfitting \n",
    "Image('pic/CV.jpg', width=700, height=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style='color: blue, font-size=12pt'> Learing Sample = Train Set = Обучающая выборка </span>  VS\n",
    "<span style='color: red, font-size=12pt'> Validation Sample = Validation Set = Контрольная выборка </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style='color: green, font-size=12pt'> Переобучение - это явление (эффект), связанное с тем, что с ростом сложности семейства алгоритмов будет ухудшаться (с некоторого момента), точность на контрольной выборке.</span>\n",
    "\n",
    "** Вопросы **\n",
    " * В чём причина переобучения?\n",
    " * Можно ли ожидать, что с ростом сложности модели ошибка на контрольной (велидационной) выборке будет только расти (неуменьшаться)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Идея разложения ошибки на bias и variance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Bias Variance Idea **\n",
    "   * Given a model $a_{LS}$ built from learning sample $LS$.\n",
    "    - Its generalization error (useful for model assessment):\n",
    "$$ Err_{LS}=E_{X,Y}\\{\\mathcal L(y, a_{LS})\\}$$\n",
    "\n",
    "   * Given a learning algorithm $\\mu$ trained on $LS$ of size $\\ell$\n",
    "     - Its error (useful to describe learning algorithm):\n",
    "    $E_{LS} {Err_{LS} }=E_{LS} \\left\\{E_{X,Y}\\{\\mathcal L(y, a_{LS})\\}\\right\\}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='img/BVIdea.jpg', Width=600>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## БЮВывод для регрессии при квадратичной функции потерь  \n",
    "* simple regression model $Err_{LS} = E_y \\left\\{(y-\\hat{y})^2\\right\\}$:\n",
    "* a good algorithm should minimize an error not only on one $LS$, but in average over all $LS$ of size $\\ell$:\n",
    "\n",
    "\\begin{equation}\n",
    "    \\begin{split}\n",
    "        &  E_{LS} \\left\\{E_{Y}\\{(y - \\hat{y})^2\\}\\right\\} = E_{LS} \\left\\{E_{Y}\\{(y - E_Y\\{y\\} + E_Y\\{y\\} - \\hat{y})^2\\}\\right\\} = \\\\\n",
    "          = & E_{LS} \\left\\{E_{Y}\\{(y - E_Y\\{y\\})^2\\}\\right\\} + E_{LS} \\left\\{E_{Y}\\{(E_Y\\{y\\} - \\hat{y})^2\\}\\right\\}+\n",
    "        2 E_{LS} \\left\\{E_{Y}\\{(y - E_Y\\{y\\}) (E_Y\\{y\\} - \\hat{y})\\}\\right\\} = \\\\\n",
    "          = & E_{Y}\\{(y - E_Y\\{y\\})^2\\} + E_{LS} \\left\\{(E_Y\\{y\\} - \\hat{y})^2\\right\\}\n",
    "        + 2 E_{LS} \\left\\{E_{Y}\\{(y - E_Y\\{y\\}) (E_Y\\{y\\} - \\hat{y})\\}\\right\\} =\\\\\n",
    "         & = \\color{red}{\\underbrace{E_{Y}\\{(y - E_Y\\{y\\})^2\\}}_{var_Y\\{y\\}}} +\\color{black}{E_{LS} \\left\\{(E_Y\\{y\\} - \\hat{y})^2\\right\\}}\n",
    "    \\end{split}\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "    \\begin{split}\n",
    "        & E_{LS} \\left\\{(E_Y\\{y\\} - \\hat{y})^2\\right\\} = E_{LS} \\left\\{(E_Y\\{y\\} - E_{LS}\\{\\hat{y}\\} + E_{LS}\\{\\hat{y}\\} - \\hat{y})^2\\right\\} = \\\\\n",
    "        & =E_{LS} \\left\\{(E_Y\\{y\\} - E_{LS}\\{\\hat{y}\\})^2\\right\\} + E_{LS} \\left\\{(E_{LS}\\{\\hat{y}\\} - \\hat{y})^2\\right\\}\n",
    "         + E_{LS} \\left\\{2 (E_Y\\{y\\} - E_{LS}\\{\\hat{y}\\})(E_{LS}\\{\\hat{y}\\} - \\hat{y})\\right\\} = \\\\\n",
    "        & =(E_Y\\{y\\} - E_{LS}\\{\\hat{y}\\})^2 + E_{LS} \\left\\{(\\hat{y}-E_{LS}\\{\\hat{y}\\})^2\\right\\} + 2 (E_Y\\{y\\} - E_{LS}\\{\\hat{y}\\})(E_{LS}\\{\\hat{y}\\} - E_{LS}\\{\\hat{y}\\}) = \\\\\n",
    "        & = \\color{red}{\\underbrace{(E_Y\\{y\\} - E_{LS}\\{\\hat{y}\\})^2 }_{bias^2}}+ \\color{red}{\\underbrace{E_{LS} \\left\\{(\\hat{y}-E_{LS}\\{\\hat{y}\\})^2\\right\\}}_{variance}}\n",
    "    \\end{split}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* более полная версия для регрессии и knn: https://github.com/ml-mipt/ml-mipt-part1/blob/master/2017/seminars/03-pandas/bias_variance.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Задача **:\n",
    "Предсказать средний рост группы 59x , которая поступит на физтех в 2025 году, зная рост всех 59x групп прошлых лет. \n",
    "\n",
    "Решение: используется 2 модели\n",
    "\n",
    "## 1) $$\\hat{y}=\\frac{1}{l}\\sum_{i=1}^l y_i$$\n",
    "## 2) $$\\hat{y}=\\frac{\\lambda\\cdot 180+\\sum_{i=1}^l y_i}{\\lambda+l}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image('pic/BiasVarianceExample.png', width=500, height=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Underfitting via Bias-Variance approach\n",
    "Image('pic/Underfitting.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overfitting via Bias-Variance approach\n",
    "Image('pic/Overfitting1.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------\n",
    "# Bias и Variance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Bias-Variance ** в зависимости от сложности модели \n",
    "<img src='img/BiasVariance.jpg' Width=500>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ** для kNN** в зависимости от $k$\n",
    "\n",
    "<img src='img/BV_knn.png', width=500, height=500>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ** для LR ** в зависимости от размера выборки \n",
    "<img src='img/BV_LR.png', width=700, height=700>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
